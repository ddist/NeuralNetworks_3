{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Tarea 3 ANN</h1>\n",
    "    <h2>Recurrent Neural Networks</h2>\n",
    "    <br>\n",
    "    <h3>Diego Pérez - 201173045-3</h3>\n",
    "    <h3>Ariel Sanhueza - ROL</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de módulos a utilizar durante los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN en series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará el dataset International Airline Passengers y el objetivo de la red a entrenar será predecir el número de pasajeros en vuelos internacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Cargar, dividir y escalar el dataset\n",
    "\n",
    "Se utilizará el MinMaxScaler en el rango (0,1), es decir, se tomará el menor y mayor valor del dataset y se asignarán como 0 y 1 respectivamente. Todos los demas valores del dataset se escalarán apropiadamente en base al máximo y mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOAD THE DATASET\n",
    "url = 'http://www.inf.utfsm.cl/~cvalle/international-airline-passengers.csv'\n",
    "dataframe = pd.read_csv(url, sep=',', usecols=[1], engine='python', skipfooter=3)\n",
    "dataframe[:] = dataframe[:].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SPLIT INTO TRAINING AND TEST SETS\n",
    "df_train, df_test = dataframe[0:96].values, dataframe[96:].values\n",
    "### SCALE BOTH SETS USING THE SAME MINMAXSCALER\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)).fit(df_train)\n",
    "stream_train_scaled = scaler.transform(df_train)\n",
    "stream_test_scaled = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos ya divididos y escalados, es necesario construir la matriz de entrada para las RNN, a partir de la serie de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Transformar entrada\n",
    "\n",
    "La siguiente función transforma un vector de entrada (serie de tiempo) considerando un lag como parámentro, para poder ser utilizado como input de las RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(ts, lag=1):\n",
    "    dataX = np.array([])\n",
    "    for index in range(lag, len(ts)):\n",
    "        dataX = np.append(dataX, np.array([ts[index-lag:index]]))\n",
    "    return dataX.reshape(len(ts)-lag, lag), ts[lag:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Crear datsets\n",
    "\n",
    "Usando lag igual a 3, se crean los dataset de entrenamiento y pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento con lag=3:  (93, 3)\n",
      "Conjunto de pruebas con lag=3:  (45, 3)\n"
     ]
    }
   ],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_dataset(stream_train_scaled, lag)\n",
    "testX, testY = create_dataset(stream_test_scaled, lag)\n",
    "print('Conjunto de entrenamiento con lag=' + str(lag) + ': ', trainX.shape)\n",
    "print('Conjunto de pruebas con lag=' + str(lag) + ': ', testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Transformación para LSTM\n",
    "\n",
    "Para poder usar el dataset en una LSTM, necesitamos entradas de la forma [samples, time steps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento con lag=3:  (93, 1, 3)\n",
      "Conjunto de pruebas con lag=3:  (45, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "print('Conjunto de entrenamiento con lag=' + str(lag) + ': ', trainX.shape)\n",
    "print('Conjunto de pruebas con lag=' + str(lag) + ': ', testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Entrenamiento\n",
    "\n",
    "Con las entradas en el formato correcto, generamos el modelo de la red, para luego entrenarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_4 (LSTM)                    (None, 4)             128         lstm_input_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             5           lstm_4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 133\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 164.00 191.00\" width=\"164pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 160,-187 160,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140676612233760 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140676612233760</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 156,-182.5 156,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-160.8\">lstm_input_4: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140676612234376 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140676612234376</title>\n",
       "<polygon fill=\"none\" points=\"29,-73.5 29,-109.5 127,-109.5 127,-73.5 29,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-87.8\">lstm_4: LSTM</text>\n",
       "</g>\n",
       "<!-- 140676612233760&#45;&gt;140676612234376 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140676612233760-&gt;140676612234376</title>\n",
       "<path d=\"M78,-146.313C78,-138.289 78,-128.547 78,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"81.5001,-119.529 78,-109.529 74.5001,-119.529 81.5001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140676612234544 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140676612234544</title>\n",
       "<polygon fill=\"none\" points=\"27,-0.5 27,-36.5 129,-36.5 129,-0.5 27,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-14.8\">dense_4: Dense</text>\n",
       "</g>\n",
       "<!-- 140676612234376&#45;&gt;140676612234544 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140676612234376-&gt;140676612234544</title>\n",
       "<path d=\"M78,-73.3129C78,-65.2895 78,-55.5475 78,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"81.5001,-46.5288 78,-36.5288 74.5001,-46.5289 81.5001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_dim=lag, activation='tanh', inner_activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inicialización de los pesos es por Gaussiana escalada, como se propone en Glorot, 2010. Para los pesos internos, se usa inicialización ortogonal, donde la matriz obtenida tiene eigenvalues igual a 1, atenuando el problema de vanishing gradient.\n",
    "Los parámetros por defecto del optimizador Adam son:\n",
    "* learning rate = 0.001\n",
    "* beta_1 = 0.9\n",
    "* beta_2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, nb_epoch=100, batch_size=1, verbose=2)\n",
    "model.save('RNN-lag3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Predicción y desnormalización.\n",
    "\n",
    "Se realiza la predicción para los conjuntos de entrenamiento y pruebas, desnormalizando los datos para obtener el error en la escala original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Optimizer weight shape (3, 4) not compatible with provided weight shape (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-37b54ae180bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# LOAD MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RNN-lag3.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# PREDICT SETS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diego/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0moptimizer_weight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0moptimizer_weight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weight_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diego/anaconda3/lib/python3.5/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     95\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                                 \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                                 'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Optimizer weight shape (3, 4) not compatible with provided weight shape (4,)"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL\n",
    "model = load_model('RNN-lag3.h5')\n",
    "# PREDICT SETS\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# DENORMALIZE PREDICTIONS\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
