{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Tarea 3 ANN</h1>\n",
    "    <h2>Recurrent Neural Networks</h2>\n",
    "    <br>\n",
    "    <h3>Diego Pérez - 201173045-3</h3>\n",
    "    <h3>Ariel Sanhueza - ROL</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de módulos a utilizar durante los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN en series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará el dataset International Airline Passengers y el objetivo de la red a entrenar será predecir el número de pasajeros en vuelos internacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Cargar, dividir y escalar el dataset\n",
    "\n",
    "Se utilizará el MinMaxScaler en el rango (0,1), es decir, se tomará el menor y mayor valor del dataset y se asignarán como 0 y 1 respectivamente. Todos los demas valores del dataset se escalarán apropiadamente en base al máximo y mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOAD THE DATASET\n",
    "url = 'http://www.inf.utfsm.cl/~cvalle/international-airline-passengers.csv'\n",
    "dataframe = pd.read_csv(url, sep=',', usecols=[1], engine='python', skipfooter=3)\n",
    "dataframe[:] = dataframe[:].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SPLIT INTO TRAINING AND TEST SETS\n",
    "df_train, df_test = dataframe[0:96].values, dataframe[96:].values\n",
    "### SCALE BOTH SETS USING THE SAME MINMAXSCALER\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)).fit(df_train)\n",
    "stream_train_scaled = scaler.transform(df_train)\n",
    "stream_test_scaled = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos ya divididos y escalados, es necesario construir la matriz de entrada para las RNN, a partir de la serie de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Transformar entrada\n",
    "\n",
    "La siguiente función transforma un vector de entrada (serie de tiempo) considerando un lag como parámentro, para poder ser utilizado como input de las RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(ts, lag=1):\n",
    "    dataX = np.array([])\n",
    "    for index in range(lag, len(ts)):\n",
    "        dataX = np.append(dataX, np.array([ts[index-lag:index]]))\n",
    "    return dataX.reshape(len(ts)-lag, lag), ts[lag:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Crear datsets\n",
    "\n",
    "Usando lag igual a 3, se crean los dataset de entrenamiento y pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento con lag=3:  (93, 3)\n",
      "Conjunto de pruebas con lag=3:  (45, 3)\n"
     ]
    }
   ],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_dataset(stream_train_scaled, lag)\n",
    "testX, testY = create_dataset(stream_test_scaled, lag)\n",
    "print('Conjunto de entrenamiento con lag=' + str(lag) + ': ', trainX.shape)\n",
    "print('Conjunto de pruebas con lag=' + str(lag) + ': ', testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Transformación para LSTM\n",
    "\n",
    "Para poder usar el dataset en una LSTM, necesitamos entradas de la forma [samples, time steps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento con lag=3:  (93, 1, 3)\n",
      "Conjunto de pruebas con lag=3:  (45, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "print('Conjunto de entrenamiento con lag=' + str(lag) + ': ', trainX.shape)\n",
    "print('Conjunto de pruebas con lag=' + str(lag) + ': ', testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Entrenamiento\n",
    "\n",
    "Con las entradas en el formato correcto, generamos el modelo de la red, para luego entrenarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_2 (LSTM)                    (None, 4)             128         lstm_input_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             5           lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 133\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 171.00 191.00\" width=\"171pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 167,-187 167,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139996745340352 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139996745340352</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 163,-182.5 163,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-160.8\">lstm_input_10: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139996745341528 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139996745341528</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-73.5 32.5,-109.5 130.5,-109.5 130.5,-73.5 32.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-87.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 139996745340352&#45;&gt;139996745341528 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139996745340352-&gt;139996745341528</title>\n",
       "<path d=\"M81.5,-146.313C81.5,-138.289 81.5,-128.547 81.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-119.529 81.5,-109.529 78.0001,-119.529 85.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139996745341136 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139996745341136</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-0.5 30.5,-36.5 132.5,-36.5 132.5,-0.5 30.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 139996745341528&#45;&gt;139996745341136 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139996745341528-&gt;139996745341136</title>\n",
       "<path d=\"M81.5,-73.3129C81.5,-65.2895 81.5,-55.5475 81.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-46.5288 81.5,-36.5288 78.0001,-46.5289 85.0001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_dim=lag, activation='tanh', inner_activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inicialización de los pesos es por Gaussiana escalada, como se propone en Glorot, 2010. Para los pesos internos, se usa inicialización ortogonal, donde la matriz obtenida tiene eigenvalues igual a 1, atenuando el problema de vanishing gradient.\n",
    "Los parámetros por defecto del optimizador Adam son:\n",
    "* learning rate = 0.001\n",
    "* beta_1 = 0.9\n",
    "* beta_2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, nb_epoch=100, batch_size=1, verbose=2)\n",
    "model.save('RNN-lag3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Predicción y desnormalización.\n",
    "\n",
    "Se realiza la predicción para los conjuntos de entrenamiento y pruebas, desnormalizando los datos para obtener el error en la escala original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD MODEL\n",
    "model = load_model('RNN-lag3.h5')\n",
    "# PREDICT SETS\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# DENORMALIZE PREDICTIONS\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 20.78 RMSE\n",
      "Test Score: 64.11 RMSE\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE ROOT MSE\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
